{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Babonin_6133",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HiKnRW_JJ5l",
        "outputId": "46e468fd-dadd-41e4-f3ca-3d2f42a5d886",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Nov  1 11:02:54 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P0    28W /  70W |    111MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-me1WjwXkmX"
      },
      "source": [
        "from __future__ import division\n",
        "from numba import cuda, float64, jit\n",
        "import time\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "thread = 32\n",
        "size = 100\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxL7mmk6bs2V",
        "outputId": "684c3e9a-90e0-4c1f-f932-e3234387fd1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "g_time = 0.\n",
        "c_time = 0.\n",
        "n = 10 # количество иттераций\n",
        "size = 100\n",
        "#генерируем матрицы\n",
        "for _ in range(n):\n",
        "  A = np.random.randint(5, size=(size, size))\n",
        "  A = A.astype(np.float64)\n",
        "  B = np.random.randint(10, size=(size, size))\n",
        "  B = B.astype(np.float64)\n",
        "\n",
        "  start = time.time()\n",
        "#передаем на gpu матрицы\n",
        "  A_global_mem = cuda.to_device(A)\n",
        "  B_global_mem = cuda.to_device(B)\n",
        "  C_global_mem = cuda.device_array((size, size))\n",
        "\n",
        "#задаем параметры куды, количество нитей в блоке, количество блоков в гриде  \n",
        "  threadsperblock = (TPB, TPB)\n",
        "  blockspergrid_x = math.ceil(A.shape[0] / threadsperblock[1])\n",
        "  blockspergrid_y = math.ceil(B.shape[1] / threadsperblock[0])\n",
        "  blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "\n",
        "#запускает gpu device\n",
        "  mult_gpu_device[blockspergrid, threadsperblock](A_global_mem, B_global_mem, C_global_mem)\n",
        " #копируем матрицу на хост, чтобы показать \n",
        "  C_g = C_global_mem.copy_to_host()\n",
        "\n",
        "  g_time += time.time() - start\n",
        "#последовательное выполнение на процессоре\n",
        "  start = time.time()\n",
        "  C_c = mult_cpu_np(A,B)\n",
        "\n",
        "  c_time += time.time() - start\n",
        "#среднее время работы gpu, cpu и размер\n",
        "print('GPU:',g_time/n)\n",
        "print('CPU:',c_time/n)\n",
        "print('size', size)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU: 0.001988387107849121\n",
            "CPU: 0.0006983041763305664\n",
            "size 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_53FooxhiHIg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}